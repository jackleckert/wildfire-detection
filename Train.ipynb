{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee021af",
   "metadata": {
    "papermill": {
     "duration": 6.746918,
     "end_time": "2022-09-04T20:00:44.011690",
     "exception": false,
     "start_time": "2022-09-04T20:00:37.264772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import libraries\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dropout, Dense,Input,  MaxPool2D, GlobalAveragePooling2D, Layer, Add\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import sklearn\n",
    "import skimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5acb7389-8080-47f8-b3d3-280dbc4400dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choose dataset and model to train\n",
    "\"\"\"\n",
    "\n",
    "#Dataset to load or build\n",
    "LOAD_DATASET = False\n",
    "SMALL_DATASET = False\n",
    "#RGB and IR images. In order to enable RGB, IR or combination, SMALL_DATASET must be set to False\n",
    "RGB = False\n",
    "IR = False\n",
    "COMBI = True\n",
    "\n",
    "if SMALL_DATASET:\n",
    "    num_classes=2\n",
    "else:\n",
    "    num_classes=3\n",
    "\n",
    "#Model to train: choose 'CNN','ResNet18' or 'ResNet_CNN'\n",
    "MODEL = 'ResNet_CNN'\n",
    "\n",
    "MODEL_FILE_NAME = 'largedata_ResNet_CNN'\n",
    "#Hyperparameters\n",
    "BATCH_SIZE = 8 \n",
    "EPOCHS = 200\n",
    "\n",
    "#Paths\n",
    "RGB_data = '../Data/254p RGB Images/'\n",
    "IR_data = '../Data/254p Thermal Images/'\n",
    "small = \"../Data/forest_fire/All\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f6f284-9853-41ac-b6f3-5394e7c9fc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function definition: load or build dataset\n",
    "\"\"\"\n",
    "#Fire (Y/N) indicates whether or not there is fire visible in 254p RGB and/or 254p Thermal frame\n",
    "#Smoke (Y/N) indicates whether smoke fills >= 50% of the 254p RGB frame (visual estimate)\n",
    "\n",
    "#Functions definition\n",
    "def get_large_data(path):\n",
    "    y = []\n",
    "    x = []\n",
    "    IDs = []\n",
    "    files = os.listdir(path)\n",
    "    for i, file in tqdm(enumerate(files)):\n",
    "        FileName = os.path.join(path, file)\n",
    "        ID =  re.findall(r\"\\d+\",FileName[-10:])[0]\n",
    "        if len(ID)>=3 and int(ID[-1])!=0:\n",
    "            if path==RGB_data:\n",
    "                os.rename(path + \"/\" +file,'../Data/RGB duplicates/'+file)\n",
    "            if path == IR_data:\n",
    "                os.rename(path + \"/\" +file,'../Data/Thermal duplicates/'+file) \n",
    "        else:\n",
    "            ID = int(ID)\n",
    "            IDs.append(ID)\n",
    "            if ID in range(1,13701):\n",
    "                y.append([1,0,0]) #NN = No fire, no smoke\n",
    "            if ID in range(13701,14700) or ID in range(15981,19803) or ID in range(19900,27184) or ID in range(27515,31295) or ID in range(31510,33598) or ID in range(33930,36551) or ID in range(38031,38154) or ID in range(41642,45280) or ID in range(51207,52287):\n",
    "                y.append([0,1,0]) # YY = Yes fire, Yes smoke\n",
    "            if ID in range(14700,15981) or ID in range(19803,19900) or ID in range(27184,27515) or ID in range(31295,31510) or ID in range(33598,33930) or ID in range(36551,38031) or ID in range(38154,41642) or ID in range(45280,51207) or ID in range(52287,53452):\n",
    "                y.append([0,0,1]) #YN = Yes fire, no smoke. \n",
    "        \n",
    "        img_file = cv2.imread(path + \"/\" +file)\n",
    "        if img_file is not None:\n",
    "            img_arr = np.asarray(img_file)\n",
    "            x.append(img_arr)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x,y,IDs\n",
    "\n",
    "\n",
    "def get_small_data(folder):\n",
    "    x = []\n",
    "    y = []\n",
    "    for folderName in os.listdir(folder):\n",
    "        if not folderName.startswith(\".\"):\n",
    "            if folderName in [\"nofire\"]:\n",
    "                label = [0,1]\n",
    "            elif folderName in [\"fire\"]:\n",
    "                label = [1,0]\n",
    "            for image_filename in tqdm(os.listdir(folder +\"/\" +folderName+\"/\")):\n",
    "                img_file = cv2.imread(folder + \"/\" +folderName + \"/\" + image_filename)\n",
    "                if img_file is not None:\n",
    "                    #img_file = skimage.transform.resize(img_file,(227,227,3), mode = \"constant\",anti_aliasing=True)\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    x.append(img_arr)\n",
    "                    y.append(label)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70094950",
   "metadata": {
    "papermill": {
     "duration": 45.742463,
     "end_time": "2022-09-04T20:01:29.765523",
     "exception": false,
     "start_time": "2022-09-04T20:00:44.023060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load or build dataset\n",
    "\"\"\"\n",
    "\n",
    "if SMALL_DATASET:\n",
    "    if LOAD_DATASET:\n",
    "        X = np.load(\"../Data/X_small.npy\")\n",
    "        y = np.load(\"../Data/y_small.npy\")\n",
    "        \n",
    "    else:\n",
    "        X,y = get_small_data(small)\n",
    "    \n",
    "        np.save(\"../Data/X_small.npy\",X)\n",
    "        np.save(\"../Data/y_small.npy\",y)\n",
    "  \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "    # Image Normalization\n",
    "    X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0\n",
    "    n=X_train.shape[1]\n",
    "    inputshape = (None,n,n,3)\n",
    "else:\n",
    "    if LOAD_DATASET:\n",
    "        X_RGB = np.load(\"../Data/X_RGB.npy\")\n",
    "        Y_RGB = np.load(\"../Data/Y_RGB.npy\")\n",
    "        IDs_RGB = np.load(\"../Data/IDs_RGB.npy\")\n",
    "        X_IR = np.load(\"../Data/X_IR.npy\")\n",
    "        Y_IR = np.load(\"../Data/Y_IR.npy\")\n",
    "        IDs_IR = np.load(\"../Data/IDs_IR.npy\")\n",
    "        \n",
    "    else:\n",
    "        X_RGB,Y_RGB,IDs_RGB = get_large_data(RGB_data)\n",
    "        X_IR,Y_IR,IDs_IR = get_large_data(IR_data)\n",
    "    \n",
    "        np.save(\"../Data/X_RGB.npy\",X_RGB)\n",
    "        np.save(\"../Data/Y_RGB.npy\",Y_RGB)\n",
    "        np.save(\"../Data/IDs_RGB.npy\",IDs_RGB)\n",
    "        np.save(\"../Data/X_IR.npy\",X_IR)\n",
    "        np.save(\"../Data/Y_IR.npy\",Y_IR)\n",
    "        np.save(\"../Data/IDs_IR.npy\",IDs_IR)\n",
    "\n",
    "    # Split the data\n",
    "    X_RGB_train, X_RGB_test, y_RGB_train, y_RGB_test = train_test_split(X_RGB,Y_RGB,test_size=0.2,shuffle=True)\n",
    "    X_RGB_train, X_RGB_valid, y_RGB_train, y_RGB_valid = train_test_split(X_RGB_train,y_RGB_train,test_size=0.2,shuffle=True)\n",
    "    # Image Normalization\n",
    "    X_RGB_train, X_RGB_valid, X_RGB_test = X_RGB_train / 255.0, X_RGB_valid / 255.0, X_RGB_test / 255.0\n",
    "    \n",
    "    # Split the data\n",
    "    X_IR_train, X_IR_test, y_IR_train, y_IR_test = train_test_split(X_IR,Y_IR,test_size=0.2,shuffle=True)\n",
    "    X_IR_train, X_IR_valid, y_IR_train, y_IR_valid = train_test_split(X_IR_train,y_IR_train,test_size=0.2,shuffle=True)\n",
    "    # Image Normalization\n",
    "    X_IR_train, X_IR_valid, X_IR_test = X_IR_train / 255.0, X_IR_valid / 255.0, X_IR_test / 255.0\n",
    "    n=X_IR_train.shape[1]\n",
    "    inputshape = (None,n,n,3)\n",
    "if COMBI:\n",
    "    #reorder the data for combi CNN\n",
    "    X_RGBs=np.zeros_like(X_RGB)\n",
    "    for i in range(len(IDs_RGB)):\n",
    "        j=np.argwhere(np.array(IDs_RGB)==IDs_IR[i])[0][0]\n",
    "        X_RGBs[i]=X_RGB[j]\n",
    "\n",
    "    # Split the data\n",
    "    X_RGB_train,X_RGB_test,X_IR_train, X_IR_test, y_train, y_test = train_test_split(X_RGBs,X_IR,Y_IR,test_size=0.2,shuffle=True)\n",
    "    X_RGB_train,X_RGB_valid,X_IR_train, X_IR_valid, y_train, y_valid = train_test_split(X_RGB_train,X_IR_train,y_train,test_size=0.2,shuffle=True)\n",
    "    # Image Normalization\n",
    "    X_RGB_train, X_RGB_valid, X_RGB_test = X_RGB_train / 255.0, X_RGB_valid / 255.0, X_RGB_test / 255.0\n",
    "    X_IR_train, X_IR_valid, X_IR_test = X_IR_train / 255.0, X_IR_valid / 255.0, X_IR_test / 255.0\n",
    "    n=X_IR_train.shape[1]\n",
    "    inputshape = [(None,n,n,3),(None,n,n,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbe2eca",
   "metadata": {
    "papermill": {
     "duration": 2.990605,
     "end_time": "2022-09-04T20:01:39.674416",
     "exception": false,
     "start_time": "2022-09-04T20:01:36.683811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Models definition using classes: CNN, CNN_combi, ResNet18, Resnet18_combi and ResNet_CNN\n",
    "\"\"\"\n",
    "class CNN(Model):\n",
    "    def __init__(self, channels: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cnn_conv1=Conv2D(96,(11,11),strides=(4, 4),activation=\"relu\")\n",
    "        self.cnn_bn1=BatchNormalization()\n",
    "        self.cnn_pool1=MaxPooling2D((3,3), strides=(2,2))\n",
    "\n",
    "        self.cnn_conv2=Conv2D(256,(5,5),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn2=BatchNormalization()\n",
    "        self.cnn_pool2=MaxPooling2D((3,3), strides=(2,2))\n",
    "\n",
    "        self.cnn_conv3=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn3=BatchNormalization()\n",
    "\n",
    "        self.cnn_conv4=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn4=BatchNormalization()\n",
    "\n",
    "        self.cnn_conv5=Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn5=BatchNormalization()\n",
    "        self.cnn_pool3=MaxPooling2D((3,3), strides=(2,2))\n",
    "        \n",
    "        self.cnn_flat=Flatten()\n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc1=Dense(4096,activation=\"relu\")\n",
    "        self.drop1=Dropout(0.5)\n",
    "\n",
    "        self.fc2=Dense(4096,activation=\"relu\")\n",
    "        self.drop2=Dropout(0.5)\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        #cnn bloc\n",
    "        out0=self.cnn_conv1(inputs)\n",
    "        out0=self.cnn_bn1(out0)\n",
    "        out0=self.cnn_pool1(out0)\n",
    "        out0=self.cnn_conv2(out0)\n",
    "        out0=self.cnn_bn2(out0)\n",
    "        out0=self.cnn_pool2(out0)\n",
    "        out0=self.cnn_conv3(out0)\n",
    "        out0=self.cnn_bn3(out0)\n",
    "        out0=self.cnn_conv4(out0)\n",
    "        out0=self.cnn_bn4(out0)\n",
    "        out0=self.cnn_conv5(out0)\n",
    "        out0=self.cnn_bn5(out0)\n",
    "        out0=self.cnn_pool3(out0)\n",
    "        out0=self.cnn_flat(out0)\n",
    "      \n",
    "\n",
    "        # Fully connected\n",
    "        out=self.fc1(out0)\n",
    "        out=self.drop1(out)\n",
    "\n",
    "        out=self.fc2(out)\n",
    "        out=self.drop2(out)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "\n",
    "class CNN_combi(Model):\n",
    "    def __init__(self, channels: int, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cnn0_conv1=Conv2D(96,(11,11),strides=(4, 4),activation=\"relu\")\n",
    "        self.cnn0_bn1=BatchNormalization()\n",
    "        self.cnn0_pool1=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn0_conv2=Conv2D(256,(5,5),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn0_bn2=BatchNormalization()\n",
    "        self.cnn0_pool2=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn0_conv3=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn0_bn3=BatchNormalization()\n",
    "        self.cnn0_conv4=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn0_bn4=BatchNormalization()\n",
    "        self.cnn0_conv5=Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn0_bn5=BatchNormalization()\n",
    "        self.cnn0_pool3=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn0_flat=Flatten()\n",
    "        \n",
    "        self.cnn1_conv1=Conv2D(96,(11,11),strides=(4, 4),activation=\"relu\")\n",
    "        self.cnn1_bn1=BatchNormalization()\n",
    "        self.cnn1_pool1=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn1_conv2=Conv2D(256,(5,5),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn1_bn2=BatchNormalization()\n",
    "        self.cnn1_pool2=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn1_conv3=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn1_bn3=BatchNormalization()\n",
    "        self.cnn1_conv4=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn1_bn4=BatchNormalization()\n",
    "        self.cnn1_conv5=Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn1_bn5=BatchNormalization()\n",
    "        self.cnn1_pool3=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn1_flat=Flatten()\n",
    "        \n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc1=Dense(4096,activation=\"relu\")\n",
    "        self.drop1=Dropout(0.5)\n",
    "\n",
    "        self.fc2=Dense(4096,activation=\"relu\")\n",
    "        self.drop2=Dropout(0.5)\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        #cnn bloc\n",
    "        out0=self.cnn0_conv1(inputs[0])\n",
    "        out0=self.cnn0_bn1(out0)\n",
    "        out0=self.cnn0_pool1(out0)\n",
    "        out0=self.cnn0_conv2(out0)\n",
    "        out0=self.cnn0_bn2(out0)\n",
    "        out0=self.cnn0_pool2(out0)\n",
    "        out0=self.cnn0_conv3(out0)\n",
    "        out0=self.cnn0_bn3(out0)\n",
    "        out0=self.cnn0_conv4(out0)\n",
    "        out0=self.cnn0_bn4(out0)\n",
    "        out0=self.cnn0_conv5(out0)\n",
    "        out0=self.cnn0_bn5(out0)\n",
    "        out0=self.cnn0_pool3(out0)\n",
    "        out0=self.cnn0_flat(out0)\n",
    "        \n",
    "        out1=self.cnn1_conv1(inputs[1])\n",
    "        out1=self.cnn1_bn1(out1)\n",
    "        out1=self.cnn1_pool1(out1)\n",
    "        out1=self.cnn1_conv2(out1)\n",
    "        out1=self.cnn1_bn2(out1)\n",
    "        out1=self.cnn1_pool2(out1)\n",
    "        out1=self.cnn1_conv3(out1)\n",
    "        out1=self.cnn1_bn3(out1)\n",
    "        out1=self.cnn1_conv4(out1)\n",
    "        out1=self.cnn1_bn4(out1)\n",
    "        out1=self.cnn1_conv5(out1)\n",
    "        out1=self.cnn1_bn5(out1)\n",
    "        out1=self.cnn1_pool3(out1)\n",
    "        out1=self.cnn1_flat(out1)\n",
    "      \n",
    "        concat = tf.keras.layers.concatenate([out0, out1], name='Concatenate')\n",
    "        \n",
    "        # Fully connected\n",
    "        out=self.fc1(concat)\n",
    "        out=self.drop1(out)\n",
    "\n",
    "        out=self.fc2(out)\n",
    "        out=self.drop2(out)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "class ResnetBlock(Model):\n",
    "\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "       \n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            # perform down sampling using stride of 2\n",
    "            self.res_conv = Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "A ResNet18 model\n",
    "\"\"\"\n",
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "         # Fully connected\n",
    "        self.fc1=Dense(4096,activation=\"relu\")\n",
    "        self.drop1=Dropout(0.5)\n",
    "\n",
    "        self.fc2=Dense(4096,activation=\"relu\")\n",
    "        self.drop2=Dropout(0.5)\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        \n",
    "        # Fully connected\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "combination of two ResNets to use RGB and Thermal images at the same time\n",
    "\"\"\"\n",
    "class ResNet18_combi(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        \n",
    "        self.conv2_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init2_bn = BatchNormalization()\n",
    "        self.pool2_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res2_1_1 = ResnetBlock(64)\n",
    "        self.res2_1_2 = ResnetBlock(64)\n",
    "        self.res2_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res2_2_2 = ResnetBlock(128)\n",
    "        self.res2_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res2_3_2 = ResnetBlock(256)\n",
    "        self.res2_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res2_4_2 = ResnetBlock(512)\n",
    "        self.avg2_pool = GlobalAveragePooling2D()\n",
    "        self.flat2 = Flatten()\n",
    "        \n",
    "         # Fully connected\n",
    "        self.fc1=Dense(4096,activation=\"relu\")\n",
    "        self.drop1=Dropout(0.5)\n",
    "\n",
    "        self.fc2=Dense(4096,activation=\"relu\")\n",
    "        self.drop2=Dropout(0.5)\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #in1 = Input(shape=(n,n,3))\n",
    "        \n",
    "        out1 = self.conv_1(inputs[0])\n",
    "        out1 = self.init_bn(out1)\n",
    "        out1 = tf.nn.relu(out1)\n",
    "        out1 = self.pool_2(out1)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out1 = res_block(out1)\n",
    "        out1 = self.avg_pool(out1)\n",
    "        out1 = self.flat(out1)\n",
    "        #model1 = Model(inputs=in1, outputs=out1)\n",
    "        \n",
    "        #in2 = Input(shape=(n,n,3))\n",
    "        out2 = self.conv2_1(inputs[1])\n",
    "        out2 = self.init2_bn(out2)\n",
    "        out2 = tf.nn.relu(out2)\n",
    "        out2 = self.pool2_2(out2)\n",
    "        for res_block in [self.res2_1_1, self.res2_1_2, self.res2_2_1, self.res2_2_2, self.res2_3_1, self.res2_3_2, self.res2_4_1, self.res2_4_2]:\n",
    "            out2 = res_block(out2)\n",
    "        out2 = self.avg2_pool(out2)\n",
    "        out2 = self.flat2(out2)\n",
    "        #model2 = Model(inputs=in2, outputs=out2)\n",
    "        \n",
    "        concat = tf.keras.layers.concatenate([out1, out2], name='Concatenate')\n",
    "        \n",
    "        # Fully connected\n",
    "        out = self.fc1(concat)\n",
    "        out = self.drop1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.drop2(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        #final_model = Model(inputs=[out1.input, out2.input], outputs=out,\n",
    "        #            name='Final_output')\n",
    "        #final_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "        return out\n",
    "\n",
    "\"\"\"\n",
    "Final model: combination of CNN for RGB images and ResNet for Thermal images\n",
    "\"\"\"\n",
    "class ResNet_CNN(Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        #bloc1\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "         \n",
    "        #bloc2\n",
    "        self.cnn_conv1=Conv2D(96,(11,11),strides=(4, 4),activation=\"relu\")\n",
    "        self.cnn_bn1=BatchNormalization()\n",
    "        self.cnn_pool1=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn_conv2=Conv2D(256,(5,5),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn2=BatchNormalization()\n",
    "        self.cnn_pool2=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn_conv3=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn3=BatchNormalization()\n",
    "        self.cnn_conv4=Conv2D(384,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn4=BatchNormalization()\n",
    "        self.cnn_conv5=Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")\n",
    "        self.cnn_bn5=BatchNormalization()\n",
    "        self.cnn_pool3=MaxPooling2D((3,3), strides=(2,2))\n",
    "        self.cnn_flat=Flatten()\n",
    "        \n",
    "        # Fully connected\n",
    "        self.fc1=Dense(4096,activation=\"relu\")\n",
    "        self.drop1=Dropout(0.5)\n",
    "\n",
    "        self.fc2=Dense(4096,activation=\"relu\")\n",
    "        self.drop2=Dropout(0.5)\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        \n",
    "        \n",
    "        #cnn bloc\n",
    "        out0=self.cnn_conv1(inputs[0])\n",
    "        out0=self.cnn_bn1(out0)\n",
    "        out0=self.cnn_pool1(out0)\n",
    "        out0=self.cnn_conv2(out0)\n",
    "        out0=self.cnn_bn2(out0)\n",
    "        out0=self.cnn_pool2(out0)\n",
    "        out0=self.cnn_conv3(out0)\n",
    "        out0=self.cnn_bn3(out0)\n",
    "        out0=self.cnn_conv4(out0)\n",
    "        out0=self.cnn_bn4(out0)\n",
    "        out0=self.cnn_conv5(out0)\n",
    "        out0=self.cnn_bn5(out0)\n",
    "        out0=self.cnn_pool3(out0)\n",
    "        out0=self.cnn_flat(out0)\n",
    "        \n",
    "        #resnet bloc\n",
    "        out1 = self.conv_1(inputs[1])\n",
    "        out1 = self.init_bn(out1)\n",
    "        out1 = tf.nn.relu(out1)\n",
    "        out1 = self.pool_2(out1)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out1 = res_block(out1)\n",
    "        out1 = self.avg_pool(out1)\n",
    "        out1 = self.flat(out1)\n",
    "        \n",
    "        concat = tf.keras.layers.concatenate([out0, out1], name='Concatenate')\n",
    "        # Fully connected\n",
    "        out=self.fc1(concat)\n",
    "        out=self.drop1(out)\n",
    "\n",
    "        out=self.fc2(out)\n",
    "        out=self.drop2(out)\n",
    "        out=self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0aad8",
   "metadata": {
    "papermill": {
     "duration": 0.130263,
     "end_time": "2022-09-04T20:01:39.919833",
     "exception": false,
     "start_time": "2022-09-04T20:01:39.789570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MODEL == 'CNN':\n",
    "    if COMBI: \n",
    "        model = CNN_combi(num_classes)\n",
    "    else:\n",
    "        model=CNN(num_classes)\n",
    "if MODEL == 'ResNet18':\n",
    "    if COMBI:\n",
    "        model = ResNet18_combi(num_classes)\n",
    "    else:\n",
    "        model = ResNet18(num_classes)\n",
    "if MODEL == 'ResNet_CNN':\n",
    "    model = ResNet_CNN(num_classes)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "model.build(input_shape = inputshape)\n",
    "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b45c5ad",
   "metadata": {
    "papermill": {
     "duration": 0.120239,
     "end_time": "2022-09-04T20:01:40.154303",
     "exception": false,
     "start_time": "2022-09-04T20:01:40.034064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True)\n",
    "# Add a checkpoint where val accuracy is max, and save that model\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(MODEL_FILE_NAME+'.keras', monitor='val_accuracy', \n",
    "                     mode='max',  verbose=1, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda73f4a",
   "metadata": {
    "papermill": {
     "duration": 59.792616,
     "end_time": "2022-09-04T20:02:40.059813",
     "exception": false,
     "start_time": "2022-09-04T20:01:40.267197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=BATCH_SIZE\n",
    "epochs=EPOCHS\n",
    "if COMBI:\n",
    "    history =  model.fit([X_RGB_train,X_IR_train],y_train,validation_data=([X_RGB_valid,X_IR_valid],y_valid),batch_size=batch_size,\n",
    "                    epochs=epochs,verbose=1,callbacks=[early_stopping])\n",
    "else:\n",
    "    if RGB:\n",
    "        history =  model.fit(X_RGB_train,y_RGB_train,validation_data=(X_RGB_valid,y_RGB_valid),batch_size=batch_size,\n",
    "                    epochs=epochs,verbose=1,callbacks=[early_stopping])\n",
    "    if IR:\n",
    "         history =  model.fit(X_IR_train,y_IR_train,validation_data=(X_IR_valid,y_IR_valid),batch_size=batch_size,\n",
    "                    epochs=epochs,verbose=1,callbacks=[early_stopping])\n",
    "    if SMALL_DATASET:\n",
    "        history =  model.fit(X_train,y_train,validation_data=(X_valid,y_valid),batch_size=batch_size,\n",
    "                    epochs=epochs,verbose=1,callbacks=[early_stopping])\n",
    "        \n",
    "        \n",
    "    \n",
    "model.save('./'+MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c546b8",
   "metadata": {
    "papermill": {
     "duration": 0.599305,
     "end_time": "2022-09-04T20:02:41.112265",
     "exception": false,
     "start_time": "2022-09-04T20:02:40.512960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_FILE_NAME)\n",
    "if COMBI:\n",
    "    score = model.evaluate([X_RGB_test,X_IR_test], y_test, batch_size=batch_size, verbose=1)\n",
    "else:\n",
    "    if RGB:\n",
    "        score = model.evaluate(X_RGB_test, y_RGB_test, batch_size=batch_size, verbose=1)\n",
    "    if IR:\n",
    "        score = model.evaluate(X_IR_test, y_IR_test, batch_size=batch_size, verbose=1)\n",
    "    if SMALL_DATASET:\n",
    "        score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "        \n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07feb402",
   "metadata": {
    "papermill": {
     "duration": 0.63397,
     "end_time": "2022-09-04T20:02:42.076639",
     "exception": false,
     "start_time": "2022-09-04T20:02:41.442669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(history.history['accuracy'], color='b')\n",
    "plt.plot(history.history['val_accuracy'], color='r')\n",
    "plt.title('Model Accuracy', weight='bold', fontsize=16)\n",
    "plt.ylabel('accuracy', weight='bold', fontsize=14)\n",
    "plt.xlabel('epoch', weight='bold', fontsize=14)\n",
    "plt.ylim(0.4, 1.0)\n",
    "#plt.xticks(weight='bold', fontsize=12)\n",
    "#plt.yticks(weight='bold', fontsize=12)\n",
    "plt.legend(['train', 'val'], loc='lower right', prop={'size': 14})\n",
    "#plt.grid(color = 'y', linewidth='0.5')\n",
    "plt.savefig('training_curve_'+MODEL_FILE_NAME+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 140.489495,
   "end_time": "2022-09-04T20:02:49.819281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-04T20:00:29.329786",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
